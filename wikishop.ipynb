{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Загрузка-и-подготовка-данных\" data-toc-modified-id=\"Загрузка-и-подготовка-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Загрузка и подготовка данных</a></span></li><li><span><a href=\"#Предобработка-текста\" data-toc-modified-id=\"Предобработка-текста-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Предобработка текста</a></span></li><li><span><a href=\"#Обучение-и-оценка-моделей\" data-toc-modified-id=\"Обучение-и-оценка-моделей-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Обучение и оценка моделей</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "import spacy\n",
    "import nltk\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.898388\n",
       "1    0.101612\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Загрузка данных\n",
    "data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "\n",
    "# Проверка данных\n",
    "display(data.head())\n",
    "display(data.info())\n",
    "display(data['toxic'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы  \n",
    "\n",
    "1. **Структура данных**:  \n",
    "   - Датасет содержит **159 292 записи** и **3 столбца**\n",
    "   - Типы данных: `int64` для числовых столбцов и `object` для текста.  \n",
    "\n",
    "2. **Распределение меток токсичности**:  \n",
    "   - **89.8%** записей (**класс 0**) — **нетоксичные** тексты.  \n",
    "   - **10.2%** записей (**класс 1**) — **токсичные** тексты.  \n",
    "   - Наблюдается **сильный дисбаланс классов**, что типично для задач классификации токсичности.  \n",
    "\n",
    "**Итог**: Далее стоит сосредоточиться на предобработке текста и методах работы с дисбалансом для построения эффективной классификационной модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка необходимых ресурсов NLTK\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для преобразования POS-тегов NLTK в формат WordNet\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # по умолчанию считаем существительным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Удаление спецсимволов\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)\n",
    "    # Приведение к нижнему регистру\n",
    "    text = text.lower()\n",
    "    # Удаление лишних пробелов\n",
    "    text = text.strip()\n",
    "    # Токенизация\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Получаем POS-теги для всех токенов\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    \n",
    "    # Лемматизация с учетом POS-тегов\n",
    "    lemmatized_tokens = []\n",
    "    for word, pos in pos_tags:\n",
    "        if word not in stop_words and len(word) > 2:  # игнорируем стоп-слова и короткие слова\n",
    "            wordnet_pos = get_wordnet_pos(pos)\n",
    "            lemma = lemmatizer.lemmatize(word, pos=wordnet_pos)\n",
    "            lemmatized_tokens.append(lemma)\n",
    "    \n",
    "    # Сборка обратно в строку\n",
    "    return ' '.join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33dc11af1aa49cba4e4ef5eb856e5d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/159292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Включаем прогресс-бар для pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# Применение предобработки с отображением прогресса\n",
    "data['processed_text'] = data['text'].progress_apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Explanation\\nWhy the edits made under my usern...   \n",
      "1  D'aww! He matches this background colour I'm s...   \n",
      "2  Hey man, I'm really not trying to edit war. It...   \n",
      "3  \"\\nMore\\nI can't make any real suggestions on ...   \n",
      "4  You, sir, are my hero. Any chance you remember...   \n",
      "5  \"\\n\\nCongratulations from me as well, use the ...   \n",
      "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
      "7  Your vandalism to the Matt Shirvington article...   \n",
      "8  Sorry if the word 'nonsense' was offensive to ...   \n",
      "9  alignment on this subject and which are contra...   \n",
      "\n",
      "                                      processed_text  \n",
      "0  explanation edits make username hardcore metal...  \n",
      "1  daww match background colour seemingly stick t...  \n",
      "2  hey man really try edit war guy constantly rem...  \n",
      "3  cant make real suggestion improvement wonder s...  \n",
      "4                sir hero chance remember page thats  \n",
      "5             congratulation well use tool well talk  \n",
      "6                        cocksucker piss around work  \n",
      "7  vandalism matt shirvington article revert plea...  \n",
      "8  sorry word nonsense offensive anyway intend wr...  \n",
      "9               alignment subject contrary dulithgow  \n"
     ]
    }
   ],
   "source": [
    "# Выводим первые 10 строк для сравнения\n",
    "print(data[['text', 'processed_text']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на признаки и целевую переменную\n",
    "X = data['processed_text']\n",
    "y = data['toxic']\n",
    "\n",
    "# Разделение на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение и оценка моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание пайплайнов для разных моделей\n",
    "models = {\n",
    "    'Logistic Regression': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=50000, ngram_range=(1, 2))),\n",
    "        ('clf', LogisticRegression(random_state=42, class_weight='balanced'))\n",
    "    ]),\n",
    "    'Random Forest': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=50000)),\n",
    "        ('clf', RandomForestClassifier(random_state=42, class_weight='balanced'))\n",
    "    ]),\n",
    "    'Linear SVM': Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=50000)),\n",
    "        ('clf', LinearSVC(random_state=42, class_weight='balanced'))\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: Средний F1 на кросс-валидации = 0.7437\n",
      "Отдельные fold-ы: [0.7408, 0.7446, 0.7459]\n",
      "Random Forest: Средний F1 на кросс-валидации = 0.6492\n",
      "Отдельные fold-ы: [0.6508, 0.6512, 0.6455]\n",
      "Linear SVM: Средний F1 на кросс-валидации = 0.7419\n",
      "Отдельные fold-ы: [0.7396, 0.7446, 0.7414]\n"
     ]
    }
   ],
   "source": [
    "# Оценка моделей с помощью кросс-валидации\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=3, scoring='f1')\n",
    "    mean_f1 = cv_scores.mean()\n",
    "    results[name] = mean_f1\n",
    "    print(f'{name}: Средний F1 на кросс-валидации = {mean_f1:.4f}')\n",
    "    print(f'Отдельные fold-ы: {[round(score, 4) for score in cv_scores]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель: Logistic Regression с F1 = 0.7437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'clf__C': 10, 'tfidf__max_features': 70000, 'tfidf__ngram_range': (1, 2)}\n",
      "Лучший F1: 0.7614\n",
      "Финальный F1 на тестовых данных: 0.7665\n"
     ]
    }
   ],
   "source": [
    "# Выбор лучшей модели\n",
    "best_model_name = max(results, key=results.get)\n",
    "print(f'Лучшая модель: {best_model_name} с F1 = {results[best_model_name]:.4f}')\n",
    "\n",
    "# Дополнительная настройка параметров для лучшей модели\n",
    "if best_model_name == 'Logistic Regression':\n",
    "    param_grid = {\n",
    "        'tfidf__max_features': [30000, 50000, 70000],\n",
    "        'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "        'clf__C': [0.1, 1, 10]\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(models[best_model_name], param_grid, cv=3, scoring='f1', n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f'Лучшие параметры: {grid_search.best_params_}')\n",
    "    print(f'Лучший F1: {grid_search.best_score_:.4f}')\n",
    "    \n",
    "    # Оценка на тестовых данных\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    final_f1 = f1_score(y_test, y_pred)\n",
    "    print(f'Финальный F1 на тестовых данных: {final_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - выбраны гиперпараметры для модели\n",
    "  - тестирование произведено корректно \n",
    "  - достигнута метрика f1 выше 0,75 на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Качество модели: Мы достигли целевого значения метрики после настройки гиперпараметров модель Logistic Regression показала F1 0.77 на тестовых данных.\n",
    "\n",
    "- Итог: Модель готова к внедрению для автоматического обнаружения токсичных комментариев в интернет-магазине \"Викишоп\".\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2464,
    "start_time": "2025-06-18T13:41:10.652Z"
   },
   {
    "duration": 1014,
    "start_time": "2025-06-18T13:41:27.874Z"
   },
   {
    "duration": 919,
    "start_time": "2025-06-18T13:42:50.789Z"
   },
   {
    "duration": 8,
    "start_time": "2025-06-18T13:42:52.793Z"
   },
   {
    "duration": 1819,
    "start_time": "2025-06-18T13:42:58.895Z"
   },
   {
    "duration": 661,
    "start_time": "2025-06-18T13:43:01.575Z"
   },
   {
    "duration": 83,
    "start_time": "2025-06-18T13:43:04.389Z"
   },
   {
    "duration": 2497,
    "start_time": "2025-06-18T14:17:48.970Z"
   },
   {
    "duration": 3,
    "start_time": "2025-06-18T14:18:01.523Z"
   },
   {
    "duration": 391,
    "start_time": "2025-06-18T14:18:33.151Z"
   },
   {
    "duration": 1315,
    "start_time": "2025-06-18T15:11:50.119Z"
   },
   {
    "duration": 24858,
    "start_time": "2025-06-18T15:12:05.232Z"
   },
   {
    "duration": 74,
    "start_time": "2025-06-18T15:12:30.092Z"
   },
   {
    "duration": 2380,
    "start_time": "2025-06-18T15:15:57.940Z"
   },
   {
    "duration": 23030,
    "start_time": "2025-06-18T15:16:00.322Z"
   },
   {
    "duration": 69,
    "start_time": "2025-06-18T15:16:23.354Z"
   },
   {
    "duration": 541253,
    "start_time": "2025-06-18T15:16:23.435Z"
   },
   {
    "duration": 6,
    "start_time": "2025-06-18T15:25:24.691Z"
   },
   {
    "duration": 64834,
    "start_time": "2025-06-18T15:27:01.612Z"
   },
   {
    "duration": 780141,
    "start_time": "2025-06-18T15:28:32.013Z"
   },
   {
    "duration": 4331,
    "start_time": "2025-06-19T16:46:25.853Z"
   },
   {
    "duration": 25503,
    "start_time": "2025-06-19T16:46:30.187Z"
   },
   {
    "duration": 78,
    "start_time": "2025-06-19T16:46:55.692Z"
   },
   {
    "duration": 571778,
    "start_time": "2025-06-19T16:46:55.772Z"
   },
   {
    "duration": 849860,
    "start_time": "2025-06-19T16:56:27.552Z"
   },
   {
    "duration": 49,
    "start_time": "2025-06-25T15:54:50.469Z"
   },
   {
    "duration": 76,
    "start_time": "2025-06-25T15:57:58.638Z"
   },
   {
    "duration": 1,
    "start_time": "2025-06-25T15:57:58.716Z"
   },
   {
    "duration": 0,
    "start_time": "2025-06-25T15:57:58.717Z"
   },
   {
    "duration": 1,
    "start_time": "2025-06-25T15:57:58.718Z"
   },
   {
    "duration": 0,
    "start_time": "2025-06-25T15:57:58.720Z"
   },
   {
    "duration": 0,
    "start_time": "2025-06-25T15:57:58.721Z"
   },
   {
    "duration": 0,
    "start_time": "2025-06-25T15:57:58.722Z"
   },
   {
    "duration": 0,
    "start_time": "2025-06-25T15:57:58.724Z"
   },
   {
    "duration": 0,
    "start_time": "2025-06-25T15:57:58.725Z"
   },
   {
    "duration": 0,
    "start_time": "2025-06-25T15:57:58.726Z"
   },
   {
    "duration": 0,
    "start_time": "2025-06-25T15:57:58.727Z"
   },
   {
    "duration": 5826,
    "start_time": "2025-06-25T16:11:07.446Z"
   },
   {
    "duration": 1048,
    "start_time": "2025-06-25T16:11:13.274Z"
   },
   {
    "duration": 625,
    "start_time": "2025-06-25T16:11:14.324Z"
   },
   {
    "duration": 4,
    "start_time": "2025-06-25T16:11:14.951Z"
   },
   {
    "duration": 53,
    "start_time": "2025-06-25T16:11:14.957Z"
   },
   {
    "duration": 39,
    "start_time": "2025-06-25T16:11:15.012Z"
   },
   {
    "duration": 516818,
    "start_time": "2025-06-25T16:11:15.053Z"
   },
   {
    "duration": 84,
    "start_time": "2025-06-25T16:19:51.873Z"
   },
   {
    "duration": 534967,
    "start_time": "2025-06-25T16:19:51.958Z"
   },
   {
    "duration": 6,
    "start_time": "2025-06-25T16:28:46.926Z"
   },
   {
    "duration": 339137,
    "start_time": "2025-06-25T16:30:20.612Z"
   },
   {
    "duration": 0,
    "start_time": "2025-06-25T16:35:59.751Z"
   },
   {
    "duration": 4021,
    "start_time": "2025-06-25T16:36:07.703Z"
   },
   {
    "duration": 944,
    "start_time": "2025-06-25T16:36:11.726Z"
   },
   {
    "duration": 211,
    "start_time": "2025-06-25T16:36:12.673Z"
   },
   {
    "duration": 4,
    "start_time": "2025-06-25T16:36:12.886Z"
   },
   {
    "duration": 9,
    "start_time": "2025-06-25T16:36:12.893Z"
   },
   {
    "duration": 5,
    "start_time": "2025-06-25T16:36:12.904Z"
   },
   {
    "duration": 136513,
    "start_time": "2025-06-25T16:36:12.910Z"
   },
   {
    "duration": 0,
    "start_time": "2025-06-25T16:38:29.425Z"
   },
   {
    "duration": 0,
    "start_time": "2025-06-25T16:38:29.426Z"
   },
   {
    "duration": 0,
    "start_time": "2025-06-25T16:38:29.427Z"
   },
   {
    "duration": 0,
    "start_time": "2025-06-25T16:38:29.428Z"
   },
   {
    "duration": 3832,
    "start_time": "2025-06-25T16:38:45.632Z"
   },
   {
    "duration": 894,
    "start_time": "2025-06-25T16:38:49.467Z"
   },
   {
    "duration": 150,
    "start_time": "2025-06-25T16:38:50.362Z"
   },
   {
    "duration": 4,
    "start_time": "2025-06-25T16:38:50.513Z"
   },
   {
    "duration": 28,
    "start_time": "2025-06-25T16:38:50.519Z"
   },
   {
    "duration": 39,
    "start_time": "2025-06-25T16:38:50.549Z"
   },
   {
    "duration": 484966,
    "start_time": "2025-06-25T16:38:50.589Z"
   },
   {
    "duration": 325,
    "start_time": "2025-06-25T16:46:55.557Z"
   },
   {
    "duration": 0,
    "start_time": "2025-06-25T16:46:55.884Z"
   },
   {
    "duration": 0,
    "start_time": "2025-06-25T16:46:55.886Z"
   },
   {
    "duration": 0,
    "start_time": "2025-06-25T16:46:55.887Z"
   },
   {
    "duration": 44,
    "start_time": "2025-06-25T16:50:11.360Z"
   },
   {
    "duration": 4373,
    "start_time": "2025-06-25T16:50:36.859Z"
   },
   {
    "duration": 875,
    "start_time": "2025-06-25T16:50:41.234Z"
   },
   {
    "duration": 152,
    "start_time": "2025-06-25T16:50:42.111Z"
   },
   {
    "duration": 4,
    "start_time": "2025-06-25T16:50:42.265Z"
   },
   {
    "duration": 14,
    "start_time": "2025-06-25T16:50:42.271Z"
   },
   {
    "duration": 22,
    "start_time": "2025-06-25T16:50:42.287Z"
   },
   {
    "duration": 431274,
    "start_time": "2025-06-25T16:50:42.311Z"
   },
   {
    "duration": 44,
    "start_time": "2025-06-25T16:57:53.586Z"
   },
   {
    "duration": 67,
    "start_time": "2025-06-25T16:57:53.632Z"
   },
   {
    "duration": 608383,
    "start_time": "2025-06-25T16:57:53.700Z"
   },
   {
    "duration": 467341,
    "start_time": "2025-06-25T17:08:02.084Z"
   },
   {
    "duration": 5,
    "start_time": "2025-06-25T17:16:00.055Z"
   },
   {
    "duration": 5,
    "start_time": "2025-06-25T17:16:10.885Z"
   },
   {
    "duration": 4197,
    "start_time": "2025-06-26T15:09:08.070Z"
   },
   {
    "duration": 1013,
    "start_time": "2025-06-26T15:09:12.269Z"
   },
   {
    "duration": 815,
    "start_time": "2025-06-26T15:09:13.283Z"
   },
   {
    "duration": 6,
    "start_time": "2025-06-26T15:09:14.100Z"
   },
   {
    "duration": 128,
    "start_time": "2025-06-26T15:09:14.108Z"
   },
   {
    "duration": 4,
    "start_time": "2025-06-26T15:09:14.238Z"
   },
   {
    "duration": 482219,
    "start_time": "2025-06-26T15:09:14.244Z"
   },
   {
    "duration": 42,
    "start_time": "2025-06-26T15:17:16.464Z"
   },
   {
    "duration": 91,
    "start_time": "2025-06-26T15:17:16.507Z"
   },
   {
    "duration": 5,
    "start_time": "2025-06-26T15:17:16.600Z"
   },
   {
    "duration": 1065215,
    "start_time": "2025-06-26T15:17:16.608Z"
   },
   {
    "duration": 1992251,
    "start_time": "2025-06-26T15:35:01.825Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
